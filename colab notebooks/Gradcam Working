{"cells":[{"cell_type":"code","source":["!pip install imutils\n","!pip install image-classifiers==1.0.0b1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z7dCWCGF1oLT","executionInfo":{"status":"ok","timestamp":1675757778539,"user_tz":-330,"elapsed":16514,"user":{"displayName":"Zahid Hussain","userId":"14872109210270963710"}},"outputId":"b87ba9fc-3a57-4955-dada-5cd57fc48bcf"},"id":"z7dCWCGF1oLT","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imutils in /usr/local/lib/python3.8/dist-packages (0.5.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting image-classifiers==1.0.0b1\n","  Downloading image_classifiers-1.0.0b1.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: image-classifiers\n","  Building wheel for image-classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for image-classifiers: filename=image_classifiers-1.0.0b1-py3-none-any.whl size=19968 sha256=afab1ba12ea448efb72ca426f8c0d909f3339519413a294af2768021b2cad861\n","  Stored in directory: /root/.cache/pip/wheels/59/ee/99/bdd974449ed4653c3c2e37d600817c9da816057dfa43c67878\n","Successfully built image-classifiers\n","Installing collected packages: image-classifiers\n","Successfully installed image-classifiers-1.0.0b1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GDdnx0bSS0lf"},"id":"GDdnx0bSS0lf","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"informative-editing","metadata":{"execution":{"iopub.execute_input":"2021-06-01T21:05:29.584067Z","iopub.status.busy":"2021-06-01T21:05:29.583218Z","iopub.status.idle":"2021-06-01T21:05:36.464971Z","shell.execute_reply":"2021-06-01T21:05:36.464133Z","shell.execute_reply.started":"2021-06-01T20:13:06.066128Z"},"papermill":{"duration":6.915082,"end_time":"2021-06-01T21:05:36.465143","exception":false,"start_time":"2021-06-01T21:05:29.550061","status":"completed"},"tags":[],"id":"informative-editing"},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from skimage import exposure\n","import matplotlib.pyplot as plt\n","import matplotlib\n","matplotlib.rcParams.update({'font.size': 16})\n","import pandas as pd \n","from matplotlib.patches import Rectangle\n","from ast import literal_eval\n","import tensorflow as tf\n","import cv2\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n","from keras.preprocessing.image import ImageDataGenerator\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import os"]},{"cell_type":"code","source":["import tensorflow as tf\n","import gc\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import VGG16, DenseNet169\n","from tensorflow.keras.layers import AveragePooling2D\n","from tensorflow.keras.layers import Dropout, GlobalAveragePooling2D, Activation, BatchNormalization, Dropout\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint,TensorBoard,TerminateOnNaN, LearningRateScheduler\n","from tensorflow.keras.losses import binary_crossentropy\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n","from tensorflow.keras.layers import Lambda, Reshape, DepthwiseConv2D, ZeroPadding2D, Add, MaxPooling2D,Activation, Flatten, Conv2D, Dense, Input, Dropout, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","from tensorflow.keras import backend as K\n","\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedStratifiedKFold\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import random\n","import shutil\n","import cv2\n","import os\n","import keras.applications\n","from datetime import datetime\n","%load_ext tensorboard"],"metadata":{"id":"Qx4eOgAJ1pwa"},"id":"Qx4eOgAJ1pwa","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade -q kaggle\n","\n","!mkdir /root/.kaggle\n","import json\n","token = {\n","    \"username\": \"zahidhussain909\",\n","    \"key\": \"39a06efd89d0f2a699143b8d3d62b216\"\n","}\n","\n","with open('/root/.kaggle/kaggle.json', 'w') as config_file:\n","    json.dump(token, config_file)\n","!chmod 600 /root/.kaggle/kaggle.json\n","\n","\n","!kaggle datasets download -d zahidhussain909/denoised-oct-balanced\n","\n","import zipfile\n","zipref=zipfile.ZipFile(\"/content/denoised-oct-balanced.zip\",'r')\n","zipref.extractall()\n","zipref.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUovHu9y1FxY","executionInfo":{"status":"ok","timestamp":1675757828838,"user_tz":-330,"elapsed":33714,"user":{"displayName":"Zahid Hussain","userId":"14872109210270963710"}},"outputId":"0d52e07e-8951-4733-dbe1-1209ab8afcb6"},"id":"GUovHu9y1FxY","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading denoised-oct-balanced.zip to /content\n","100% 1.04G/1.05G [00:08<00:00, 149MB/s]\n","100% 1.05G/1.05G [00:08<00:00, 140MB/s]\n"]}]},{"cell_type":"code","source":["class_to_label_map = {'cnv' : 0, 'dme' : 1, 'drusen' : 2, 'normal' : 3}"],"metadata":{"id":"jWqFkP1X1F1D"},"id":"jWqFkP1X1F1D","execution_count":null,"outputs":[]},{"cell_type":"code","source":["samples = 500"],"metadata":{"id":"GZZMPUQ61N7e"},"id":"GZZMPUQ61N7e","execution_count":null,"outputs":[]},{"cell_type":"code","source":["normal_dataset_path = '/content/DENOISED OCT/train/NORMAL'\n","cnv_dataset_path = '/content/DENOISED OCT/train/CNV'\n","dme_dataset_path = '/content/DENOISED OCT/train/DME'\n","drusen_dataset_path = '/content/DENOISED OCT/train/DRUSEN'"],"metadata":{"id":"YyIv4oiI1N-N"},"id":"YyIv4oiI1N-N","execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_path = '/content/dataset'\n","log_path = '/content/logs'\n","\n","!mkdir dataset\n","!mkdir logs\n","\n","dataset_path = '/content/dataset'\n","log_path = '/content/logs'\n","\n"],"metadata":{"id":"ex6E_t661OBb"},"id":"ex6E_t661OBb","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir dataset/cnv\n","!mkdir dataset/normal"],"metadata":{"id":"YFG76DEG1OD3"},"id":"YFG76DEG1OD3","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir dataset/dme\n","!mkdir dataset/drusen"],"metadata":{"id":"6VvBzQ4I1OG1"},"id":"6VvBzQ4I1OG1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["basePath = normal_dataset_path\n","imagePaths = list(paths.list_images(basePath))\n","random.seed(42)\n","random.shuffle(imagePaths)\n","imagePaths = imagePaths[:samples]\n","for (i, imagePath) in enumerate(imagePaths):\n","    filename = imagePath.split(os.path.sep)[-1]\n","    outputPath = os.path.sep.join([f\"{dataset_path}/normal\", filename])\n","    shutil.copy2(imagePath, outputPath)"],"metadata":{"id":"HCOYPRMG1UE9"},"id":"HCOYPRMG1UE9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["basePath = cnv_dataset_path\n","imagePaths = list(paths.list_images(basePath))\n","random.seed(42)\n","random.shuffle(imagePaths)\n","imagePaths = imagePaths[:samples]\n","for (i, imagePath) in enumerate(imagePaths):\n","    filename = imagePath.split(os.path.sep)[-1]\n","    outputPath = os.path.sep.join([f\"{dataset_path}/cnv\", filename])\n","    shutil.copy2(imagePath, outputPath)"],"metadata":{"id":"zvLHaiQO1UKe"},"id":"zvLHaiQO1UKe","execution_count":null,"outputs":[]},{"cell_type":"code","source":["basePath = dme_dataset_path\n","imagePaths = list(paths.list_images(basePath))\n","random.seed(42)\n","random.shuffle(imagePaths)\n","imagePaths = imagePaths[:samples]\n","for (i, imagePath) in enumerate(imagePaths):\n","    filename = imagePath.split(os.path.sep)[-1]\n","    outputPath = os.path.sep.join([f\"{dataset_path}/dme\", filename])\n","    shutil.copy2(imagePath, outputPath)\n"],"metadata":{"id":"v1khzaxU1UQO"},"id":"v1khzaxU1UQO","execution_count":null,"outputs":[]},{"cell_type":"code","source":["basePath = drusen_dataset_path\n","imagePaths = list(paths.list_images(basePath))\n","random.seed(42)\n","random.shuffle(imagePaths)\n","imagePaths = imagePaths[:samples]\n","for (i, imagePath) in enumerate(imagePaths):\n","    filename = imagePath.split(os.path.sep)[-1]\n","    outputPath = os.path.sep.join([f\"{dataset_path}/drusen\", filename])\n","    shutil.copy2(imagePath, outputPath)"],"metadata":{"id":"2J6GvM9q1UUi"},"id":"2J6GvM9q1UUi","execution_count":null,"outputs":[]},{"cell_type":"code","source":["normal_images = list(paths.list_images(f\"{dataset_path}/normal\"))\n","cnv_images = list(paths.list_images(f\"{dataset_path}/cnv\"))\n","dme_images = list(paths.list_images(f\"{dataset_path}/dme\"))\n","drusen_images = list(paths.list_images(f\"{dataset_path}/drusen\"))"],"metadata":{"id":"7MrBrEgN1dLN"},"id":"7MrBrEgN1dLN","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"loading images...\")\n","imagePaths = list(paths.list_images(dataset_path))\n","data = []\n","labels = []\n","for imagePath in imagePaths:\n","\n","    label = imagePath.split(os.path.sep)[-2]\n","\n","    image = cv2.imread(imagePath)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    image = cv2.resize(image, (180, 180), interpolation = cv2.INTER_AREA)\n","   \n","    data.append(image)\n","    labels.append(class_to_label_map[label])\n","\n","data = np.array(data) / 255.0\n","labels = np.array(labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DMHKcuQf1dN6","executionInfo":{"status":"ok","timestamp":1675757835037,"user_tz":-330,"elapsed":4975,"user":{"displayName":"Zahid Hussain","userId":"14872109210270963710"}},"outputId":"6b162e75-b202-48fb-ef7b-173a434c503f"},"id":"DMHKcuQf1dN6","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading images...\n"]}]},{"cell_type":"code","source":["(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.15, stratify=labels, random_state=42)\n","\n","train_datagen = ImageDataGenerator(\n","                                   rotation_range=60,\n","                                   horizontal_flip = True ,\n","                                   vertical_flip = True ,\n","                                   fill_mode='nearest')\n","\n","val_datagen = ImageDataGenerator()"],"metadata":{"id":"FIepq_a72F3t"},"id":"FIepq_a72F3t","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_image(img):\n","    equ_img = exposure.equalize_hist(img)\n","    return equ_img\n","\n","img_size = 180\n","batch_size = 16\n","\n","image_generator = ImageDataGenerator(\n","        validation_split=0.2,\n","        #rotation_range=20,\n","        horizontal_flip = True,\n","        zoom_range = 0.1,\n","        #shear_range = 0.1,\n","        brightness_range = [0.8, 1.1],\n","        fill_mode='nearest',\n","        preprocessing_function=preprocess_image\n",")\n","\n","image_generator_valid = ImageDataGenerator(validation_split=0.2,preprocessing_function=preprocess_image)\n","\n","train_generator1 = image_generator.flow_from_directory(\n","       '/content/dataset',\n","\n","        target_size=(img_size, img_size),\n","        batch_size=batch_size,\n","        subset='training', seed = 23) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xdkxvIU83SY7","executionInfo":{"status":"ok","timestamp":1675757841032,"user_tz":-330,"elapsed":473,"user":{"displayName":"Zahid Hussain","userId":"14872109210270963710"}},"outputId":"e0c48aa9-e177-40b7-8baf-144a07ae2e2e"},"id":"xdkxvIU83SY7","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1600 images belonging to 4 classes.\n"]}]},{"cell_type":"code","execution_count":null,"id":"mechanical-value","metadata":{"execution":{"iopub.execute_input":"2021-06-01T21:05:44.509011Z","iopub.status.busy":"2021-06-01T21:05:44.507923Z","iopub.status.idle":"2021-06-01T21:05:44.510430Z","shell.execute_reply":"2021-06-01T21:05:44.510915Z","shell.execute_reply.started":"2021-06-01T20:13:19.630319Z"},"papermill":{"duration":0.029392,"end_time":"2021-06-01T21:05:44.511104","exception":false,"start_time":"2021-06-01T21:05:44.481712","status":"completed"},"tags":[],"id":"mechanical-value"},"outputs":[],"source":["def load_process(img, img_size):\n","    img = load_img(img, target_size = (img_size, img_size))\n","    img = img_to_array(img)\n","    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n","    img = preprocess_image(img)\n","    return img"]},{"cell_type":"markdown","id":"dying-lawrence","metadata":{"papermill":{"duration":0.02055,"end_time":"2021-06-01T21:05:44.552641","exception":false,"start_time":"2021-06-01T21:05:44.532091","status":"completed"},"tags":[],"id":"dying-lawrence"},"source":["# Main Grad-CAM algorithm"]},{"cell_type":"code","execution_count":null,"id":"victorian-punishment","metadata":{"execution":{"iopub.execute_input":"2021-06-01T21:05:44.597869Z","iopub.status.busy":"2021-06-01T21:05:44.597194Z","iopub.status.idle":"2021-06-01T21:05:44.604257Z","shell.execute_reply":"2021-06-01T21:05:44.604721Z","shell.execute_reply.started":"2021-06-01T20:13:26.890351Z"},"papermill":{"duration":0.031197,"end_time":"2021-06-01T21:05:44.604906","exception":false,"start_time":"2021-06-01T21:05:44.573709","status":"completed"},"tags":[],"id":"victorian-punishment"},"outputs":[],"source":["def grad_cam(input_image, model, layer_name):\n","\n","    desired_layer = model.get_layer(layer_name)\n","    grad_model = Model(model.inputs, [desired_layer.output, model.output])\n","\n","    with tf.GradientTape() as tape:\n","        layer_output, preds = grad_model(input_image)\n","        ix = (np.argsort(preds, axis=1)[:, -1]).item()\n","        output_idx = preds[:, ix]\n","\n","    gradient = tape.gradient(output_idx, layer_output)\n","    alpha_kc = np.mean(gradient, axis=(0,1,2))\n","    L_gradCam = tf.nn.relu(np.dot(layer_output, alpha_kc)[0])\n","    L_gradCam = (L_gradCam - np.min(L_gradCam)) / (np.max(L_gradCam) - np.min(L_gradCam)) \n","    return L_gradCam.numpy()"]},{"cell_type":"markdown","id":"quick-marathon","metadata":{"papermill":{"duration":0.0206,"end_time":"2021-06-01T21:05:44.646322","exception":false,"start_time":"2021-06-01T21:05:44.625722","status":"completed"},"tags":[],"id":"quick-marathon"},"source":["# Blend\n","\n","Superimposing gradCAM heatmap on the original image"]},{"cell_type":"code","execution_count":null,"id":"killing-welcome","metadata":{"execution":{"iopub.execute_input":"2021-06-01T21:05:44.692004Z","iopub.status.busy":"2021-06-01T21:05:44.691399Z","iopub.status.idle":"2021-06-01T21:05:44.697008Z","shell.execute_reply":"2021-06-01T21:05:44.697567Z","shell.execute_reply.started":"2021-06-01T20:13:26.901032Z"},"papermill":{"duration":0.029274,"end_time":"2021-06-01T21:05:44.697758","exception":false,"start_time":"2021-06-01T21:05:44.668484","status":"completed"},"tags":[],"id":"killing-welcome"},"outputs":[],"source":["def blend(img_path, gradCam_img, alpha, colormap = cv2.COLORMAP_JET):\n","    origin_img = img_to_array(load_img(img_path))\n","    gradCam_resized = cv2.resize(gradCam_img, (origin_img.shape[1], origin_img.shape[0]), interpolation = cv2.INTER_LINEAR)\n","    heatmap  = cv2.applyColorMap(np.uint8(gradCam_resized*255), colormap)\n","    superimposed_image = cv2.cvtColor(origin_img.astype('uint8'), cv2.COLOR_RGB2BGR) + heatmap * alpha\n","    return heatmap, superimposed_image"]},{"cell_type":"code","execution_count":null,"id":"decimal-hamilton","metadata":{"execution":{"iopub.execute_input":"2021-06-01T21:05:44.783712Z","iopub.status.busy":"2021-06-01T21:05:44.783101Z","iopub.status.idle":"2021-06-01T21:05:51.632556Z","shell.execute_reply":"2021-06-01T21:05:51.632010Z"},"papermill":{"duration":6.872696,"end_time":"2021-06-01T21:05:51.632704","exception":false,"start_time":"2021-06-01T21:05:44.760008","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"decimal-hamilton","executionInfo":{"status":"ok","timestamp":1675757854772,"user_tz":-330,"elapsed":656,"user":{"displayName":"Zahid Hussain","userId":"14872109210270963710"}},"outputId":"88c25cbb-5433-4a75-c395-e50238392d87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 178, 178, 100)     2800      \n","                                                                 \n"," batch_normalization (BatchN  (None, 178, 178, 100)    400       \n"," ormalization)                                                   \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 59, 59, 100)      0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 57, 57, 70)        63070     \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 57, 57, 70)       280       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 28, 28, 70)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 26, 26, 50)        31550     \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 26, 26, 50)       200       \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 13, 13, 50)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 11, 11, 20)        9020      \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 11, 11, 20)       80        \n"," hNormalization)                                                 \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 5, 5, 20)         0         \n"," 2D)                                                             \n","                                                                 \n"," dropout (Dropout)           (None, 5, 5, 20)          0         \n","                                                                 \n"," flatten (Flatten)           (None, 500)               0         \n","                                                                 \n"," dense (Dense)               (None, 4)                 2004      \n","                                                                 \n","=================================================================\n","Total params: 109,404\n","Trainable params: 108,924\n","Non-trainable params: 480\n","_________________________________________________________________\n"]}],"source":["trained_model = load_model('/content/classify_model4.h5')\n","trained_model.summary()"]},{"cell_type":"code","source":["files1=[]\n","import os\n","path_of_the_directory= '/content/dataset/drusen'\n","print(\"Files and directories in a specified path:\")\n","for filename in os.listdir(path_of_the_directory):\n","    f = os.path.join(path_of_the_directory,filename)\n","    if os.path.isfile(f):\n","        files1.append(f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OdAWDAHmA2n_","executionInfo":{"status":"ok","timestamp":1675757863302,"user_tz":-330,"elapsed":12,"user":{"displayName":"Zahid Hussain","userId":"14872109210270963710"}},"outputId":"c99972f8-1b08-43eb-8ad6-830f822ad266"},"id":"OdAWDAHmA2n_","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files and directories in a specified path:\n"]}]},{"cell_type":"code","execution_count":null,"id":"recorded-valuable","metadata":{"execution":{"iopub.execute_input":"2021-06-01T21:05:51.731606Z","iopub.status.busy":"2021-06-01T21:05:51.730622Z","iopub.status.idle":"2021-06-01T21:05:51.733516Z","shell.execute_reply":"2021-06-01T21:05:51.733040Z","shell.execute_reply.started":"2021-06-01T20:34:44.735210Z"},"papermill":{"duration":0.037833,"end_time":"2021-06-01T21:05:51.733663","exception":false,"start_time":"2021-06-01T21:05:51.695830","status":"completed"},"tags":[],"id":"recorded-valuable"},"outputs":[],"source":["train_dir='/content/dataset/cnv'\n","def plot_results(model, gen):\n","    n = 50\n","    train_dir = '/content/dataset/cnv'\n","    fig, axs = plt.subplots(10, 5, figsize=(20,60))\n","    fig.subplots_adjust(hspace=.5, wspace=.1)\n","    axs = axs.ravel()\n","    gen.next()\n","    classes = list(gen.class_indices.keys()) \n","    idx = gen.index_array\n","    layer_name = 'max_pooling2d_3'\n","    for i in range(n):\n","        sample_img_path = files1[i]\n","        img = load_process(sample_img_path, img_size)\n","        pred = model.predict(img)\n","        grad_cam_img = grad_cam(img, model, layer_name)\n","        heatmap_img, result_img = blend(sample_img_path, grad_cam_img, 0.5)\n","        axs[i].imshow(result_img[:,:,::-1]/255)\n","        axs[i].set_xticklabels([])\n","        axs[i].set_yticklabels([])"]},{"cell_type":"code","execution_count":null,"id":"traditional-speech","metadata":{"execution":{"iopub.execute_input":"2021-06-01T21:05:51.833969Z","iopub.status.busy":"2021-06-01T21:05:51.831216Z","iopub.status.idle":"2021-06-01T21:07:08.139523Z","shell.execute_reply":"2021-06-01T21:07:08.140150Z","shell.execute_reply.started":"2021-06-01T20:34:46.970667Z"},"papermill":{"duration":76.344066,"end_time":"2021-06-01T21:07:08.140363","exception":false,"start_time":"2021-06-01T21:05:51.796297","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Yoe4zzm5ZLloQW_WrzlyxqCQFCOsFNMP"},"id":"traditional-speech","executionInfo":{"status":"ok","timestamp":1675758525489,"user_tz":-330,"elapsed":27022,"user":{"displayName":"Zahid Hussain","userId":"14872109210270963710"}},"outputId":"616c69a2-5767-48e8-8cae-314ff3cf1266"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["plot_results(trained_model, train_generator1)"]},{"cell_type":"code","source":[],"metadata":{"id":"AeEvKMnA9qea"},"id":"AeEvKMnA9qea","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":342.151723,"end_time":"2021-06-01T21:11:03.342389","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2021-06-01T21:05:21.190666","version":"2.3.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}