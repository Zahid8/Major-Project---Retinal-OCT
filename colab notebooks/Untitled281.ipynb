{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPt3ETpg/tHTAxhpKhpAR2g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"BqyNuaUCQvC-","executionInfo":{"status":"ok","timestamp":1680558843033,"user_tz":-330,"elapsed":6088,"user":{"displayName":"Zahid Hussain","userId":"14872109210270963710"}}},"outputs":[],"source":["from tensorflow.keras.utils import normalize\n","import os\n","import glob\n","import cv2 as cv\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import sys\n","import random\n","import os\n","from keras.preprocessing import image\n","import tensorflow as tf \n","import keras \n","import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import keras\n","import tensorflow as tf\n","np.set_printoptions(threshold=sys.maxsize)"]},{"cell_type":"code","source":["!pip install --upgrade -q kaggle\n","\n","!mkdir /root/.kaggle\n","import json\n","token = {\n","    \"username\": \"zahidhussain909\",\n","    \"key\": \"39a06efd89d0f2a699143b8d3d62b216\"\n","}\n","\n","with open('/root/.kaggle/kaggle.json', 'w') as config_file:\n","    json.dump(token, config_file)\n","!chmod 600 /root/.kaggle/kaggle.json\n","\n","!kaggle datasets download -d zahidhussain909/retina-segmentation-saved-model\n","!kaggle datasets download -d mohamedberrimi/oct-images-balanced-version\n","!kaggle datasets download -d zahidhussain909/best-model-oct-denoising\n","\n","import zipfile\n","zipref=zipfile.ZipFile(\"/content/retina-segmentation-saved-model.zip\",'r')\n","zipref.extractall()\n","zipref.close()\n","zipref=zipfile.ZipFile(\"/content/oct-images-balanced-version.zip\",'r')\n","zipref.extractall()\n","zipref.close()\n","zipref=zipfile.ZipFile(\"/content/best-model-oct-denoising.zip\",'r')\n","zipref.extractall()\n","zipref.close()\n","\n","!rm -rf /content/retina-segmentation-saved-model.zip\n","!rm -rf /content/oct-images-balanced-version.zip\n","!rm -rf /content/best-model-oct-denoising.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Uk8Mv49GcME","executionInfo":{"status":"ok","timestamp":1680558954532,"user_tz":-330,"elapsed":111522,"user":{"displayName":"Zahid Hussain","userId":"14872109210270963710"}},"outputId":"c08add7a-b6eb-4524-d068-acf57972e6c8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading retina-segmentation-saved-model.zip to /content\n","100% 21.0M/21.0M [00:00<00:00, 51.2MB/s]\n","100% 21.0M/21.0M [00:00<00:00, 44.6MB/s]\n","Downloading oct-images-balanced-version.zip to /content\n","100% 4.15G/4.15G [00:39<00:00, 111MB/s]\n","100% 4.15G/4.15G [00:39<00:00, 112MB/s]\n","Downloading best-model-oct-denoising.zip to /content\n"," 69% 5.00M/7.21M [00:00<00:00, 34.6MB/s]\n","100% 7.21M/7.21M [00:00<00:00, 46.1MB/s]\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","model = tf.keras.models.load_model('/content/retina_segmentation_8_layer (1).hdf5')"],"metadata":{"id":"y7pSwhY5GcOq","executionInfo":{"status":"ok","timestamp":1680558956487,"user_tz":-330,"elapsed":1970,"user":{"displayName":"Zahid Hussain","userId":"14872109210270963710"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","model_den = tf.keras.models.load_model(\"/content/best_model_OCT_denoising.h5\")"],"metadata":{"id":"T_TW-bQJGcRb","executionInfo":{"status":"ok","timestamp":1680558956489,"user_tz":-330,"elapsed":22,"user":{"displayName":"Zahid Hussain","userId":"14872109210270963710"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["test_test = []\n","val_image = []\n","\n","orig_path = '/content/dme_seg/'\n","\n","SIZE_X = 640\n","SIZE_Y = 640\n","\n","SIZE_x = 180\n","SIZE_y = 180\n","\n","n_classes= 9 \n","\n","test_path = \"/content/oct_balanced_version/Balanced/NORMAL\"\n","\n","val_images = sorted(os.listdir('/content/OCT_Balanced_Version/Balanced/NORMAL'))\n","im_base='/content/OCT_Balanced_Version/Balanced/NORMAL/'\n","val_images = val_images[:100]\n","for im in val_images:\n","    img_path = im_base + im\n","\n","    val_image = []\n","    img = tf.keras.utils.load_img(img_path, target_size=(180,180), color_mode= 'grayscale')\n","    img = tf.keras.utils.img_to_array(img)\n","    img = img/255\n","    val_image.append(img)\n","    train_df = np.array(val_image)\n","    img = cv.imread(img_path, 0)       \n","    img = cv.resize(img, (SIZE_y, SIZE_x))\n","    pred= model_den.predict(train_df)\n","    pred=np.reshape(pred, (180,180))\n","    orig_img=img\n","    den_img=pred\n","\n","    dst = cv.medianBlur(pred,1)\n","    blurred = cv.GaussianBlur(dst, (17,17), 0)\n","    ret,th2 = cv.threshold(blurred,0.215,1,cv.ADAPTIVE_THRESH_MEAN_C)\n","    th2[th2!=0] = 255\n","    thresh_img= np.multiply(th2,orig_img)\n","    \n","    img = cv2.resize(thresh_img, (SIZE_Y, SIZE_X))\n","    #test_test.append(img) \n","    np.append(test_test,img)\n","    test_test = np.array(test_test)\n","\n","    test_test = np.expand_dims(test_test, axis=3)\n","    test_test = normalize(test_test, axis=1)\n","    test1 = test_test[0]\n","    test_img_norm=test1[:,:,0][:,:,None]\n","    test=np.expand_dims(test_img_norm, 0)\n","    prediction = (model.predict(test))\n","    predicted_img = np.argmax(prediction, axis=3)[0,:,:]\n","\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(predicted_img, cmap='jet')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"eCD7g62UGcVK","executionInfo":{"status":"error","timestamp":1680561755606,"user_tz":-330,"elapsed":1186,"user":{"displayName":"Zahid Hussain","userId":"14872109210270963710"}},"outputId":"2b4e80b0-8a09-4b1d-a48e-10998f2b6f3e"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 579ms/step\n"]},{"output_type":"error","ename":"AxisError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-dc3f3f162e20>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtest_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtest_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mtest_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mtest_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mtest1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0mout_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_ndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0mshape_it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mnormalize_axis_tuple\u001b[0;34m(axis, ndim, argname, allow_duplicate)\u001b[0m\n\u001b[1;32m   1389\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1389\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAxisError\u001b[0m: axis 3 is out of bounds for array of dimension 3"]}]},{"cell_type":"code","source":["test_test = []\n","val_image = []\n","\n","orig_path = '/content/dme_seg/'\n","\n","SIZE_X = 640\n","SIZE_Y = 640\n","\n","SIZE_x = 180\n","SIZE_y = 180\n","\n","n_classes= 9 \n","\n","test_path = \"/content/oct_balanced_version/Balanced/NORMAL\"\n","\n","val_images = sorted(os.listdir('/content/OCT_Balanced_Version/Balanced/NORMAL'))\n","im_base='/content/OCT_Balanced_Version/Balanced/NORMAL/'\n","val_images = val_images[:100]\n","for im in val_images:\n","    img_path = im_base + im\n","\n","    val_image = []\n","    img = tf.keras.utils.load_img(img_path, target_size=(180,180), color_mode= 'grayscale')\n","    img = tf.keras.utils.img_to_array(img)\n","    img = img/255\n","    val_image.append(img)\n","    train_df = np.array(val_image)\n","    img = cv.imread(img_path, 0)       \n","    img = cv.resize(img, (SIZE_y, SIZE_x))\n","    pred= model_den.predict(train_df)\n","    pred=np.reshape(pred, (180,180))\n","    orig_img=img\n","    den_img=pred\n","\n","    dst = cv.medianBlur(pred,1)\n","    blurred = cv.GaussianBlur(dst, (17,17), 0)\n","    ret,th2 = cv.threshold(blurred,0.215,1,cv.ADAPTIVE_THRESH_MEAN_C)\n","    th2[th2!=0] = 255\n","    thresh_img= np.multiply(th2,orig_img)\n","\n","    img = cv2.resize(thresh_img, (SIZE_Y, SIZE_X))\n","    test_test = np.array(img)\n","    #test_test = np.expand_dims(test_test, axis=3)\n","    test_test = normalize(test_test, axis=1)\n","    test1 = test_test[0]\n","    test_img_norm=test1[:,:,0][:,:,None]\n","    test=np.expand_dims(test_img_norm, 0)\n","    prediction = (model.predict(test))\n","    predicted_img = np.argmax(prediction, axis=3)[0,:,:]\n","\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(predicted_img, cmap='jet')\n"],"metadata":{"id":"lwN4gWBdM6sm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"85femcB2GcW_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0uxZ4Yi-GcZu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TIpzwS94Gccr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wD-glZpAGcfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gBp42phrGckH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"D4pVvTv2GcnK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L1s84ktkGcqy"},"execution_count":null,"outputs":[]}]}